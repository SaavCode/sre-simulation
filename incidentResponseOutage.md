# ğŸ§¾ Incident Report: Flask App Outage

**Service:** Local Flask App  
**Environment:** Localhost (dev/test)  
**Date:** June 1, 2025  
**Monitored by:** Prometheus  
**Visualized in:** Grafana  
**Restarted by:** Supervisor  
**Detected at:** 1:00 PM  
**Resolved at:** 1:03 PM  
**Duration:** ~3 minutes  
**Severity:** Critical  
**Status:** Resolved

---

## ğŸ” Summary

The Flask-based application (`flask_app`) serving Prometheus metrics on port `5009` experienced an unexpected shutdown. This triggered a Prometheus alert (via Grafana) due to the `up{job="flask_app"}` metric returning `0`. Supervisor auto-restarted the app within seconds, and service availability was restored without manual intervention.

---

## ğŸ“ˆ Detection

- **Prometheus Metric:** `up{job="flask_app"} = 0`
- **Grafana Alert Rule:**

  ```
  WHEN up{job="flask_app"} IS BELOW 1
  ```

- **Evaluation frequency:** 15s  
- **Alert Status:** Firing â†’ Resolved

---

## ğŸ› ï¸ Root Cause

The application was manually terminated to simulate a failure. No bugs or misconfigurations caused the crash â€” this was part of an SRE response test.

---

## ğŸ” Response

1. Grafana detected the failure via Prometheus.
2. Supervisor attempted to restart the process multiple times.
3. Flask app was successfully restarted and re-entered the RUNNING state.
4. Prometheus confirmed `up = 1`; alert resolved automatically in Grafana.

---

## âœ… Resolution Steps

- No manual intervention required.
- `supervisord` logged restart attempts and successful recovery:

  ```
  INFO spawned: 'flask_app'
  WARN exited: flask_app (exit status 1)
  INFO success: flask_app entered RUNNING state
  ```

---

## ğŸ§  Lessons Learned

- Prometheus + Grafana alerts provided real-time visibility.
- Supervisor was effective at auto-restarting a failed service.
- A single metric (`up`) can be sufficient for basic service liveness detection in local/dev environments.

---

## ğŸ”„ Recommendations

- Add log forwarding or persistent storage for service logs.
- Consider using `systemd`, Docker healthchecks, or Kubernetes probes for production-level process management.
- Extend alerting to include request duration and exception counts.
